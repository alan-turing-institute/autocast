{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08c9060",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e37fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from auto_cast.data.dataset import BOUTDataset\n",
    "from auto_cast.data.datamodule import SpatioTemporalDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_cast.data.dataset import BOUTDataset\n",
    "from auto_cast.data.datamodule import SpatioTemporalDataModule\n",
    "\n",
    "# Load with datamodule\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    data_path=\"data/bout_split\",\n",
    "    dataset_cls=BOUTDataset,\n",
    "    n_steps_input=5,   # Use 5 input frames\n",
    "    n_steps_output=40,  # Predict 5 future frames\n",
    "    stride=1,\n",
    "    batch_size=4,\n",
    "    dtype=torch.float32,  # Convert from float64 to float32\n",
    "    ftype=\"torch\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.input_fields.shape, batch.output_fields.shape, batch.constant_scalars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3366b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from azula.noise import CosineSchedule\n",
    "from auto_cast.data.dataset import BOUTDataset\n",
    "from auto_cast.data.datamodule import SpatioTemporalDataModule\n",
    "from auto_cast.types import EncodedBatch\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Load Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Loading BOUT Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    data_path=\"data/bout_split\",\n",
    "    dataset_cls=BOUTDataset,\n",
    "    n_steps_input=5,\n",
    "    n_steps_output=5,\n",
    "    stride=1,\n",
    "    batch_size=4,\n",
    "    dtype=torch.float32,\n",
    "    ftype=\"torch\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"\\nðŸ“Š Batch shapes (after collate_batches):\")\n",
    "print(f\"   Input:  {batch.input_fields.shape}\")   # Should be [4, 5, 1, 256, 256]\n",
    "print(f\"   Output: {batch.output_fields.shape}\")  # Should be [4, 5, 1, 256, 256]\n",
    "print(f\"   Const scalars: {batch.constant_scalars.shape if batch.constant_scalars is not None else None}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ff778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azula.nn.unet import UNet\n",
    "from azula.nn.embedding import SineEncoding\n",
    "\n",
    "class TemporalUNetBackbone(nn.Module):\n",
    "    \"\"\"Azula UNet with proper time embedding.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 1,\n",
    "        out_channels: int = 1,\n",
    "        mod_features: int = 256,\n",
    "        hid_channels: tuple = (32, 64, 128),\n",
    "        hid_blocks: tuple = (2, 2, 2),\n",
    "        spatial: int = 2,\n",
    "        periodic: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embedding = nn.Sequential(\n",
    "            SineEncoding(mod_features),\n",
    "            nn.Linear(mod_features, mod_features),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(mod_features, mod_features),\n",
    "        )\n",
    "        \n",
    "        self.unet = UNet(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            cond_channels=0,\n",
    "            mod_features=mod_features,\n",
    "            hid_channels=hid_channels,\n",
    "            hid_blocks=hid_blocks,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            spatial=spatial,\n",
    "            periodic=periodic,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, C, H, W = x.shape\n",
    "        \n",
    "        # Embed time\n",
    "        t_emb = self.time_embedding(t)  # (B, mod_features)\n",
    "        \n",
    "        # Flatten temporal\n",
    "        x_flat = x.reshape(B * T, C, H, W)\n",
    "        t_emb_expanded = t_emb.repeat_interleave(T, dim=0)\n",
    "        \n",
    "        # Process\n",
    "        out_flat = self.unet(x_flat, mod=t_emb_expanded)\n",
    "        \n",
    "        # Reshape\n",
    "        return out_flat.reshape(B, T, C, H, W)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ecca2",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 3. Create DiffusionProcessor\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_cast.processors.diffusion import DiffusionProcessor\n",
    "\n",
    "B, T, C, H, W = batch.output_fields.shape\n",
    "\n",
    "# Create backbone\n",
    "backbone = TemporalUNetBackbone(\n",
    "    in_channels=C,\n",
    "    out_channels=C,\n",
    "    mod_features=256,\n",
    "    hid_channels=(16, 32, 64),  # Small for testing\n",
    "    hid_blocks=(2, 2, 2),\n",
    "    spatial=2,\n",
    "    periodic=False,\n",
    ")\n",
    "# Create schedule\n",
    "schedule = CosineSchedule(alpha_min=0.001, sigma_min=0.001)\n",
    "\n",
    "# Create processor\n",
    "processor = DiffusionProcessor(\n",
    "    backbone=backbone,\n",
    "    schedule=schedule,\n",
    "    denoiser_type='karras',\n",
    "    learning_rate=1e-4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c558faab",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 4. Test Forward Pass\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11179e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoded batch\n",
    "encoded_batch = EncodedBatch(\n",
    "    encoded_inputs=batch.input_fields,\n",
    "    encoded_output_fields=batch.output_fields,\n",
    "    encoded_info={}\n",
    ")\n",
    "\n",
    "# Test training step\n",
    "loss = processor.training_step(encoded_batch, 0)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test map (prediction)\n",
    "output = processor.map(batch.input_fields)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Expected shape: {batch.input_fields.shape}\")\n",
    "assert output.shape == batch.input_fields.shape, \"Shape mismatch!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aff841",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 5. Quick Training Loop\n",
    "# ============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e5297",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 6. Visualize Results\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d52f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "processor.eval()\n",
    "\n",
    "# Get a test batch\n",
    "test_batch = next(iter(train_loader))\n",
    "test_encoded = EncodedBatch(\n",
    "    encoded_inputs=test_batch.input_fields,\n",
    "    encoded_output_fields=test_batch.output_fields,\n",
    "    encoded_info={}\n",
    ")\n",
    "\n",
    "# Get ground truth and prediction\n",
    "with torch.no_grad():\n",
    "    # Ground truth\n",
    "    x_gt = test_batch.output_fields  # (B, T, C, H, W)\n",
    "    \n",
    "    # Prediction (denoised at t=0)\n",
    "    x_pred = processor.map(test_batch.input_fields)\n",
    "    \n",
    "    # Noisy samples at different noise levels\n",
    "    B = x_gt.shape[0]\n",
    "    t_levels = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "    noisy_samples = []\n",
    "    \n",
    "    for t_val in t_levels:\n",
    "        t = torch.full((B,), t_val, device=x_gt.device)\n",
    "        alpha_t, sigma_t = processor.schedule(t)\n",
    "        alpha_t = alpha_t.view(-1, 1, 1, 1, 1)\n",
    "        sigma_t = sigma_t.view(-1, 1, 1, 1, 1)\n",
    "        noise = torch.randn_like(x_gt)\n",
    "        x_noisy = alpha_t * x_gt + sigma_t * noise\n",
    "        noisy_samples.append(x_noisy)\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "x_gt_np = x_gt[0, 0, 0].cpu().numpy()       # First batch, first time, first channel\n",
    "x_pred_np = x_pred[0, 0, 0].cpu().numpy()\n",
    "noisy_np = [x[0, 0, 0].cpu().numpy() for x in noisy_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fef65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Shared colorbar settings\n",
    "cbar_kw = {'fraction': 0.03, 'pad': 0.02}\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 1: Ground Truth vs Prediction\n",
    "# ============================================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 2.5), dpi=100)\n",
    "im0 = axes[0].imshow(x_gt_np, cmap='viridis')\n",
    "axes[0].set_title('Ground Truth', fontsize=9)\n",
    "plt.colorbar(im0, ax=axes[0], **cbar_kw)\n",
    "\n",
    "im1 = axes[1].imshow(x_pred_np, cmap='viridis')\n",
    "axes[1].set_title('Prediction', fontsize=9)\n",
    "plt.colorbar(im1, ax=axes[1], **cbar_kw)\n",
    "\n",
    "plt.suptitle('BOUT Vorticity Field', fontsize=10, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 2: Noise Schedule (Compact)\n",
    "# ============================================================================\n",
    "fig, axes = plt.subplots(1, len(t_levels), figsize=(10, 1.8), dpi=100)\n",
    "for idx, (t_val, noisy) in enumerate(zip(t_levels, noisy_np)):\n",
    "    im = axes[idx].imshow(noisy, cmap='viridis')\n",
    "    axes[idx].set_title(f't={t_val:.1f}', fontsize=8)\n",
    "\n",
    "plt.suptitle('Forward Diffusion', fontsize=10, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 3: Error Analysis (Compact)\n",
    "# ============================================================================\n",
    "error = np.abs(x_gt_np - x_pred_np)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 2.2), dpi=100)\n",
    "\n",
    "im0 = axes[0].imshow(x_gt_np, cmap='viridis')\n",
    "axes[0].set_title('Ground Truth', fontsize=9)\n",
    "\n",
    "im1 = axes[1].imshow(x_pred_np, cmap='viridis')\n",
    "axes[1].set_title('Prediction', fontsize=9)\n",
    "\n",
    "im2 = axes[2].imshow(error, cmap='Reds')\n",
    "axes[2].set_title(f'Error (MAE={error.mean():.3f})', fontsize=9)\n",
    "\n",
    "plt.suptitle('Prediction Quality', fontsize=10, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# Statistics (Compact)\n",
    "# ============================================================================\n",
    "with torch.no_grad():\n",
    "    mse = ((x_gt - x_pred) ** 2).mean().item()\n",
    "    mae = (x_gt - x_pred).abs().mean().item()\n",
    "\n",
    "print(f\"MSE:        {mse:.6f}\")\n",
    "print(f\"MAE:        {mae:.6f}\")\n",
    "print(f\"GT Range:   [{x_gt.min().item():.3f}, {x_gt.max().item():.3f}]\")\n",
    "print(f\"Pred Range: [{x_pred.min().item():.3f}, {x_pred.max().item():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b27a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Plot 4: Time Series Comparison (Every 10 Steps)\n",
    "# ============================================================================\n",
    "\n",
    "# Show every 10th time step\n",
    "T = x_gt.shape[1]  # Total number of time steps\n",
    "step_size = 1\n",
    "time_indices = list(range(0, T, step_size))\n",
    "if time_indices[-1] != T - 1:  # Always include the last frame\n",
    "    time_indices.append(T - 1)\n",
    "\n",
    "n_frames = len(time_indices)\n",
    "fig, axes = plt.subplots(2, n_frames, figsize=(4*n_frames, 8))\n",
    "\n",
    "# Handle case where we only have 1 frame\n",
    "if n_frames == 1:\n",
    "    axes = axes.reshape(2, 1)\n",
    "\n",
    "for plot_idx, t_idx in enumerate(time_indices):\n",
    "    # Ground truth\n",
    "    gt_frame = x_gt[0, t_idx, 0].cpu().numpy()\n",
    "    im0 = axes[0, plot_idx].imshow(gt_frame, cmap='viridis')\n",
    "    axes[0, plot_idx].set_title(f'GT t={t_idx}', fontsize=12)\n",
    "    if plot_idx == n_frames - 1:  # Add colorbar to last plot\n",
    "        plt.colorbar(im0, ax=axes[0, plot_idx], fraction=0.046)\n",
    "    \n",
    "    # Prediction\n",
    "    pred_frame = x_pred[0, t_idx, 0].cpu().numpy()\n",
    "    im1 = axes[1, plot_idx].imshow(pred_frame, cmap='viridis')\n",
    "    axes[1, plot_idx].set_title(f'Pred t={t_idx}', fontsize=12)\n",
    "    if plot_idx == n_frames - 1:  # Add colorbar to last plot\n",
    "        plt.colorbar(im1, ax=axes[1, plot_idx], fraction=0.046)\n",
    "\n",
    "axes[0, 0].set_ylabel('Ground Truth', fontsize=14, rotation=0, ha='right', va='center')\n",
    "axes[1, 0].set_ylabel('Prediction', fontsize=14, rotation=0, ha='right', va='center')\n",
    "\n",
    "plt.suptitle(f'Temporal Evolution (Every {step_size} Steps)', fontsize=16, y=0.99)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf37041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, Image as IPImage\n",
    "\n",
    "\n",
    "# Get data for video\n",
    "x_gt_video = x_gt[0, :, 0].cpu().numpy()    # (T, H, W)\n",
    "x_pred_video = x_pred[0, :, 0].cpu().numpy()  # (T, H, W)\n",
    "T = x_gt_video.shape[0]\n",
    "\n",
    "# Determine common color scale\n",
    "vmin = min(x_gt_video.min(), x_pred_video.min())\n",
    "vmax = max(x_gt_video.max(), x_pred_video.max())\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), dpi=80)\n",
    "\n",
    "# Initial frames\n",
    "im0 = axes[0].imshow(x_gt_video[0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axes[0].set_title('Ground Truth', fontsize=12)\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.03, pad=0.02)\n",
    "\n",
    "im1 = axes[1].imshow(x_pred_video[0], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axes[1].set_title('Prediction', fontsize=12)\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.03, pad=0.02)\n",
    "\n",
    "# Time text\n",
    "time_text = fig.suptitle(f'Time Step: 0/{T-1}', fontsize=13, y=0.98)\n",
    "\n",
    "def update(frame):\n",
    "    \"\"\"Update function for animation.\"\"\"\n",
    "    im0.set_data(x_gt_video[frame])\n",
    "    im1.set_data(x_pred_video[frame])\n",
    "    time_text.set_text(f'Time Step: {frame}/{T-1}')\n",
    "    return [im0, im1, time_text]\n",
    "\n",
    "# Create animation\n",
    "anim = FuncAnimation(fig, update, frames=T, interval=100, blit=False, repeat=True)\n",
    "\n",
    "# Display the GIF in notebook\n",
    "display(IPImage(anim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69818450",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# ROLLOUT TRAINING - Multi-step Autoregressive Prediction\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba29297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration Setup ---\n",
    "# Note: You need to set n_steps_output high enough to cover the max_rollout_steps\n",
    "# (10 steps * 4 output frames/step = 40 total frames needed for full supervision).\n",
    "\n",
    "TOTAL_GT_FRAMES = 40  # Must be 4 * 10\n",
    "\n",
    "# Load data with sufficient output steps for full rollout supervision\n",
    "datamodule_rollout = SpatioTemporalDataModule(\n",
    "    data_path=\"data/bout_split\",\n",
    "    dataset_cls=BOUTDataset,\n",
    "    n_steps_input=1,      # 1 input frame\n",
    "    n_steps_output=TOTAL_GT_FRAMES, # 40 output frames (REQUIRED for 10-step supervision)\n",
    "    stride=1,              \n",
    "    batch_size=4,          \n",
    "    dtype=torch.float32,\n",
    "    ftype=\"torch\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_loader_rollout = datamodule_rollout.train_dataloader()\n",
    "\n",
    "\n",
    "# Optional: Add a validation step here calling a separate inference function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ebbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create processor with rollout settings\n",
    "processor_rollout = DiffusionProcessor(\n",
    "    # ... (backbone, schedule, denoiser_type must be defined previously)\n",
    "    # Using placeholders here:\n",
    "    backbone=backbone,\n",
    "    schedule=schedule,\n",
    "    denoiser_type='karras',\n",
    "    teacher_forcing_ratio=0.5,  # 50% teacher forcing\n",
    "    stride=1,\n",
    "    max_rollout_steps=10,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "processor_rollout.train()\n",
    "optimizer = torch.optim.Adam(processor_rollout.parameters(), lr=1e-4)\n",
    "\n",
    "# --- Autoregressive Training Loop ---\n",
    "\n",
    "for step in range(100):\n",
    "    # Ensure all components (optimizer, schedule, etc.) are defined before this loop\n",
    "    \n",
    "    # 1. Fetch and package batch\n",
    "    # We must use a 'try-except' block to restart the iterator when it runs out of data\n",
    "    try:\n",
    "        batch = next(iter(train_loader_rollout))\n",
    "    except StopIteration:\n",
    "        train_loader_rollout = datamodule_rollout.train_dataloader()\n",
    "        batch = next(iter(train_loader_rollout))\n",
    "        \n",
    "    encoded_batch = EncodedBatch(\n",
    "        encoded_inputs=batch.input_fields,\n",
    "        encoded_output_fields=batch.output_fields,\n",
    "        encoded_info={}\n",
    "    )\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 2. Use the new, loss-accumulating rollout for training \n",
    "    # This single call executes 10 prediction steps and returns the mean accumulated loss.\n",
    "    # It does NOT return predictions or ground_truth tensors.\n",
    "    loss = processor_rollout.rollout(encoded_batch)    \n",
    "    # 3. Optimization Step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f\"   Step {step}: Autoregressive Rollout Loss (Mean Diffusion) = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745dadd",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# TEST ROLLOUT - Generate Full Time Series\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_rollout.eval()\n",
    "\n",
    "# Get a test batch\n",
    "test_batch = next(iter(train_loader_rollout))\n",
    "test_encoded = EncodedBatch(\n",
    "    encoded_inputs=test_batch.input_fields,\n",
    "    encoded_output_fields=test_batch.output_fields,\n",
    "    encoded_info={}\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get rollout predictions\n",
    "    predictions, ground_truth = processor_rollout.rollout(test_encoded)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Rollout Results:\")\n",
    "    print(f\"   Input shape:       {test_batch.input_fields.shape}\")\n",
    "    print(f\"   Predictions shape: {predictions.shape}\")\n",
    "    print(f\"   Ground truth shape: {ground_truth.shape if ground_truth is not None else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc897959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# VISUALIZE ROLLOUT - Full Time Series Video\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Creating Rollout Video\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "# Get full time series data\n",
    "x_gt_full = ground_truth[0, :, 0].cpu().numpy()     # (T_total, H, W)\n",
    "x_pred_full = predictions[0, :, 0].cpu().numpy()     # (T_total, H, W)\n",
    "T_full = x_gt_full.shape[0]\n",
    "\n",
    "print(f\"\\nðŸŽ¬ Creating animation with {T_full} frames...\")\n",
    "\n",
    "# Common color scale\n",
    "vmin = min(x_gt_full.min(), x_pred_full.min())\n",
    "vmax = max(x_gt_full.max(), x_pred_full.max())\n",
    "\n",
    "# Create compact figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), dpi=100)\n",
    "\n",
    "# Initial frames\n",
    "im0 = axes[0].imshow(x_gt_full[0].squeeze(), cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axes[0].set_title('Ground Truth', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.03, pad=0.02)\n",
    "\n",
    "im1 = axes[1].imshow(x_pred_full[0].squeeze(), cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "axes[1].set_title('Rollout Prediction', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.03, pad=0.02)\n",
    "\n",
    "# Time text with error\n",
    "time_text = fig.suptitle(f'Time Step: 0/{T_full-1} | MAE: 0.000', fontsize=13, y=0.98)\n",
    "\n",
    "def update(frame):\n",
    "    \"\"\"Update function for animation.\"\"\"\n",
    "    im0.set_data(x_gt_full[frame])\n",
    "    im1.set_data(x_pred_full[frame])\n",
    "    \n",
    "    # Compute error for this frame\n",
    "    mae = np.abs(x_gt_full[frame].squeeze() - x_pred_full[frame].squeeze()).mean()\n",
    "    time_text.set_text(f'Time Step: {frame}/{T_full-1} | MAE: {mae:.4f}')\n",
    "    \n",
    "    return [im0, im1, time_text]\n",
    "\n",
    "# Create animation\n",
    "anim = FuncAnimation(fig, update, frames=T_full, interval=100, repeat=True)\n",
    "anim.save('rollout_video.gif', writer='pillow', fps=10, dpi=100)\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ… Rollout video saved: rollout_video.gif\")\n",
    "\n",
    "# Display in notebook\n",
    "display(IPImage('rollout_video.gif'))\n",
    "\n",
    "# ============================================================================\n",
    "# ROLLOUT ERROR ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Rollout Error Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compute error over time\n",
    "with torch.no_grad():\n",
    "    mse_per_frame = ((ground_truth - predictions) ** 2).mean(dim=[0, 2, 3, 4]).cpu().numpy()\n",
    "    mae_per_frame = (ground_truth - predictions).abs().mean(dim=[0, 2, 3, 4]).cpu().numpy()\n",
    "\n",
    "# Plot error over time\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), dpi=100)\n",
    "\n",
    "axes[0].plot(mse_per_frame, marker='o', linewidth=2, markersize=4)\n",
    "axes[0].set_xlabel('Time Step', fontsize=11)\n",
    "axes[0].set_ylabel('MSE', fontsize=11)\n",
    "axes[0].set_title('Mean Squared Error over Time', fontsize=12)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(mae_per_frame, marker='o', linewidth=2, markersize=4, color='orange')\n",
    "axes[1].set_xlabel('Time Step', fontsize=11)\n",
    "axes[1].set_ylabel('MAE', fontsize=11)\n",
    "axes[1].set_title('Mean Absolute Error over Time', fontsize=12)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Rollout Error Accumulation', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rollout_error_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"âœ… Saved: rollout_error_analysis.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nðŸ“Š Rollout Statistics:\")\n",
    "print(f\"   Initial MAE:  {mae_per_frame[0]:.6f}\")\n",
    "print(f\"   Final MAE:    {mae_per_frame[-1]:.6f}\")\n",
    "print(f\"   Mean MAE:     {mae_per_frame.mean():.6f}\")\n",
    "print(f\"   Error growth: {mae_per_frame[-1] / mae_per_frame[0]:.2f}x\")\n",
    "\n",
    "# ============================================================================\n",
    "# SIDE-BY-SIDE COMPARISON: Single-Step vs Rollout\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Comparison: Single-Step vs Rollout\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Single-step prediction (original)\n",
    "with torch.no_grad():\n",
    "    single_step_pred = processor.map(test_batch.input_fields)\n",
    "\n",
    "# Plot comparison at different time points\n",
    "time_points = [0, T_full//4, T_full//2, 3*T_full//4, T_full-1]\n",
    "\n",
    "fig, axes = plt.subplots(3, len(time_points), figsize=(15, 8), dpi=100)\n",
    "\n",
    "for idx, t in enumerate(time_points):\n",
    "    if t < single_step_pred.shape[1]:\n",
    "        # Ground truth\n",
    "        axes[0, idx].imshow(x_gt_full[t].squeeze(), cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "        axes[0, idx].set_title(f't={t}', fontsize=10)\n",
    "        axes[0, idx].axis('off')\n",
    "        \n",
    "        # Single-step\n",
    "        single_frame = single_step_pred[0, min(t, single_step_pred.shape[1]-1), 0].cpu().numpy()\n",
    "        axes[1, idx].imshow(single_frame, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "        axes[1, idx].axis('off')\n",
    "        \n",
    "        # Rollout\n",
    "        axes[2, idx].imshow(x_pred_full[t].squeeze(), cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "        axes[2, idx].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('Ground Truth', fontsize=11, rotation=0, ha='right', va='center')\n",
    "axes[1, 0].set_ylabel('Single-Step', fontsize=11, rotation=0, ha='right', va='center')\n",
    "axes[2, 0].set_ylabel('Rollout', fontsize=11, rotation=0, ha='right', va='center')\n",
    "\n",
    "plt.suptitle('Prediction Comparison Over Time', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_single_vs_rollout.png', dpi=150, bbox_inches='tight')\n",
    "print(\"âœ… Saved: comparison_single_vs_rollout.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Rollout testing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687ef73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-cast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
