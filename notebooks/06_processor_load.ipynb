{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## AutoCast Processor Evaluation\n",
    "\n",
    "This notebook evaluates a pre-trained processor model on the MiniWell dataset.\n",
    "It loads the model configuration and weights from a specified run directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import hydra\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from hydra.utils import instantiate\n",
    "from IPython.display import HTML\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from autocast.external.lola.lola_autoencoder import get_autoencoder\n",
    "from autocast.models.processor import ProcessorModel\n",
    "from autocast.utils.plots import plot_spatiotemporal_video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the run directory\n",
    "run_path = \"../outputs/rayleigh_benard/2026-01-14_diffusion_vit_small\"\n",
    "config_path = os.path.join(run_path, \"resolved_processor_config.yaml\")\n",
    "ckpt_path = os.path.join(run_path, \"processor.ckpt\")\n",
    "\n",
    "# Load configuration\n",
    "cfg = OmegaConf.load(config_path)\n",
    "# print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate DataModule and setup\n",
    "datamodule = instantiate(cfg.data)\n",
    "datamodule.setup() # Setup all stages (fit for train/val, test for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Processor\n",
    "processor = instantiate(cfg.model.processor)\n",
    "\n",
    "# Instantiate ProcessorModelWrapper\n",
    "model = ProcessorModel(\n",
    "    processor=processor,\n",
    "    learning_rate=cfg.model.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test set evaluation\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "trainer = L.Trainer(accelerator=device, logger=False)\n",
    "# trainer.test(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch for visualization from validation set\n",
    "dl = datamodule.val_dataloader()\n",
    "batch = next(iter(dl))\n",
    "\n",
    "# Move to device\n",
    "# batch = batch.to(device)\n",
    "# model = model.to(device)\n",
    "\n",
    "print(f\"Batch shape inputs: {batch.encoded_inputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rollout\n",
    "with torch.no_grad():\n",
    "    preds, trues = [], []\n",
    "    for i, batch in enumerate(datamodule.val_dataloader()):\n",
    "        pred = model(batch.encoded_inputs, batch.global_cond)\n",
    "        preds.append(pred)\n",
    "        trues.append(batch.encoded_output_fields)\n",
    "        if i >= 5:  # Limit to 5 batches for speed\n",
    "            break\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    trues = torch.cat(trues, dim=0)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Ground Truth shape: {trues.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Decoded Evaluation\n",
    "\n",
    "Load the corresponding AutoEncoder to decode the latent predictions back to pixel space and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot latent space predictions\n",
    "# anim = plot_spatiotemporal_video(\n",
    "#     true=trues,\n",
    "#     pred=preds,\n",
    "#     batch_idx=0,\n",
    "#     save_path=None,\n",
    "#     title=\"Latent Space Prediction\",\n",
    "#     colorbar_mode=\"row\",\n",
    "# )\n",
    "# HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Latent Space Evaluation\n",
    "\n",
    "Visualize the predictions in the latent space (before decoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(0, preds.shape[0]-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "preds_plot = rearrange(preds[::4, ...], \"b t ... -> 1 (b t) ...\")\n",
    "trues_plot = rearrange(trues[::4, ...], \"b t ... -> 1 (b t) ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decoded\n",
    "anim = plot_spatiotemporal_video(\n",
    "    true=trues_plot[..., :4],\n",
    "    pred=preds_plot[..., :4],\n",
    "    batch_idx=0,\n",
    "    save_path=None,\n",
    "    title=\"Latent Prediction\",\n",
    "    colorbar_mode=\"row\",\n",
    ")\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AutoEncoder to decode predictions\n",
    "ae_path = \"../datasets/rayleigh_benard/1e3z5x2c_rayleigh_benard_dcae_f32c64_large\"\n",
    "ae_config_path = os.path.join(ae_path, \"config.yaml\")\n",
    "ae_ckpt_path = os.path.join(ae_path, \"state.pth\")\n",
    "\n",
    "print(f\"Loading AutoEncoder from: {ae_path}\")\n",
    "ae_cfg = OmegaConf.load(ae_config_path)\n",
    "\n",
    "# Convert to dictionary to avoid OmegaConf/beartype conflicts for most args (like attention_heads)\n",
    "ae_config_dict = OmegaConf.to_container(ae_cfg.ae, resolve=True)\n",
    "\n",
    "# However, get_autoencoder specifically types 'loss' as DictConfig, so we must preserve it\n",
    "if \"loss\" in ae_cfg.ae:\n",
    "    ae_config_dict[\"loss\"] = ae_cfg.ae.loss\n",
    "\n",
    "# Instantiate AutoEncoder\n",
    "# We pass **ae_config_dict to unpack arguments\n",
    "autoencoder = get_autoencoder(**ae_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions and ground truth\n",
    "from einops import rearrange\n",
    "\n",
    "preds_decodeds, trues_decodeds = [], []\n",
    "with torch.no_grad():\n",
    "    bs = 4\n",
    "    # for i in range(0, preds.shape[0], bs):\n",
    "    for i in range(0, 4, bs):\n",
    "        print(f\"Decoding batch {i} to {i+bs} / {preds.shape[0]}\")\n",
    "\n",
    "        preds_subset = preds[i*bs:i*bs+bs]\n",
    "        trues_subset = trues[i*bs:i*bs+bs]\n",
    "\n",
    "        # preds shape is likely (B, T, H_lat, W_lat, C_lat)\n",
    "        # We need to flatten B and T, and move C to the second dimension for the\n",
    "        # decoder:\n",
    "        #   - (B*T, C, H, W)\n",
    "        preds_flat = rearrange(preds_subset, \"b t h w c -> (b t) c h w\")\n",
    "        trues_flat = rearrange(trues_subset, \"b t h w c -> (b t) c h w\")\n",
    "\n",
    "\n",
    "        print(f\"Decoding shape: {preds_flat.shape}\")\n",
    "\n",
    "        # Pass noisy=False to deterministically decode\n",
    "        preds_decoded = autoencoder.decode(preds_flat, noisy=False)\n",
    "        trues_decoded = autoencoder.decode(trues_flat, noisy=False)\n",
    "        preds_decodeds.append(preds_decoded)\n",
    "        trues_decodeds.append(trues_decoded)\n",
    "\n",
    "preds_decodeds = torch.cat(preds_decodeds, dim=0)\n",
    "trues_decodeds = torch.cat(trues_decodeds, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_decodeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues_decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trues_decoded[0, 3, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decode output is (B*T, C_out, H_out, W_out)\n",
    "# We must use n_samples for b, not preds.shape[0]\n",
    "preds_decoded = rearrange(\n",
    "    preds_decoded, \"(b t) c h w -> b t w h c\", b=preds_decoded.shape[0] // preds.shape[1], t=preds.shape[1]\n",
    ")\n",
    "trues_decoded = rearrange(\n",
    "    trues_decoded, \"(b t) c h w -> b t w h c\", b=trues_decoded.shape[0] // trues.shape[1], t=trues.shape[1]\n",
    ")\n",
    "\n",
    "print(f\"Decoded Predictions shape: {preds_decoded.shape}\")\n",
    "\n",
    "# Plot decoded\n",
    "anim = plot_spatiotemporal_video(\n",
    "    true=trues_decoded,\n",
    "    pred=preds_decoded,\n",
    "    batch_idx=0,\n",
    "    save_path=None,\n",
    "    title=\"Decoded Prediction\",\n",
    "    colorbar_mode=\"row\",\n",
    ")\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load decoded videos for better visualization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
