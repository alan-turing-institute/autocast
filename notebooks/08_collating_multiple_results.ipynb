{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Collating Outputs from Multiple Experiments\n",
    "\n",
    "This notebook demos how to collate results from multiple experiments into one place\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Firstly, import the RunCollator class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocast.scripts.utils import RunCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where multiple runs are stored\n",
    "OUTPUTS_DIR = \"../../isambard-ai/outputs\"\n",
    "\n",
    "# Parameters to extract from the config files\n",
    "params = {\n",
    "    \"processor_model\": \"model.processor._target_\",\n",
    "    \"processor_hidden_channels\": \"model.processor.hidden_channels\",\n",
    "}\n",
    "\n",
    "collator = RunCollator(config_params=params, outputs_dir=OUTPUTS_DIR)\n",
    "\n",
    "# Set dave csv to true to save the collated results as a csv file in the current directory\n",
    "df = collator.collate(save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_lookup = pd.read_excel(\n",
    "    \"~/ati/AutoEmulate - Documents/autocast_results/2026-02-19_autocast.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = df.merge(df_lookup, left_on=\"run_name\", right_on=\"Run Name\", how=\"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"run_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = [\n",
    "    \"Short name\",\n",
    "    \"overall_vrmse\",\n",
    "    \"vrmse_0-1\",\n",
    "    \"vrmse_6-12\",\n",
    "    \"vrmse_13-30\",\n",
    "    \"vrmse_31-99\",\n",
    "    \"overall_coverage\",\n",
    "    \"coverage_0-1\",\n",
    "    \"coverage_6-12\",\n",
    "    \"coverage_13-30\",\n",
    "    \"coverage_31-99\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[out_cols].round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: we can view the coverage plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Videos of the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "By Default, all the performance metrics are collected as well as any run parameters specified in the params dictionary.\n",
    "If a parameter can't be found for that run, then its filled with a N/A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
