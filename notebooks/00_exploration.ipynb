{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## AutoCast encoder-processor-decoder model API Exploration\n",
    "\n",
    "This notebook aims to explore the end-to-end API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Example dataaset\n",
    "\n",
    "We use the `AdvectionDiffusion` dataset as an example dataset to illustrate training and evaluation of models. This dataset simulates the advection-diffusion equation in 2D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.simulations.advection_diffusion import AdvectionDiffusion as Sim\n",
    "\n",
    "sim = Sim(return_timeseries=True, log_level=\"error\")\n",
    "\n",
    "\n",
    "def generate_split(simulator: Sim, n_train: int = 10, n_valid: int = 2, n_test: int = 2):\n",
    "    \"\"\"Generate training, validation, and test splits from the simulator.\"\"\"\n",
    "    train = simulator.forward_samples_spatiotemporal(n_train)\n",
    "    valid = simulator.forward_samples_spatiotemporal(n_valid)\n",
    "    test = simulator.forward_samples_spatiotemporal(n_test)\n",
    "    return {\"train\": train, \"valid\": valid, \"test\": test}\n",
    "\n",
    "\n",
    "combined_data = generate_split(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Read combined data into datamodule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_cast.data.datamodule import SpatioTemporalDataModule\n",
    "\n",
    "n_steps_input = 4\n",
    "n_steps_output = 1\n",
    "datamodule = SpatioTemporalDataModule(\n",
    "    data=combined_data,\n",
    "    data_path=None,\n",
    "    n_steps_input=n_steps_input,\n",
    "    n_steps_output=n_steps_output,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568c131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Example batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(datamodule.train_dataloader()))\n",
    "\n",
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_cast.decoders.channels_last import ChannelsLast\n",
    "from auto_cast.encoders.permute_concat import PermuteConcat\n",
    "from auto_cast.models.encoder_decoder import EncoderDecoder\n",
    "from auto_cast.models.encoder_processor_decoder import EncoderProcessorDecoder\n",
    "from auto_cast.nn.fno import FNOProcessor\n",
    "\n",
    "batch = next(iter(datamodule.train_dataloader()))\n",
    "n_channels = batch.input_fields.shape[-1]\n",
    "processor = FNOProcessor(\n",
    "    in_channels=n_channels * n_steps_input,\n",
    "    out_channels=n_channels * n_steps_output,\n",
    "    n_modes=(16, 16),\n",
    "    hidden_channels=64,\n",
    ")\n",
    "encoder = PermuteConcat(with_constants=False)\n",
    "decoder = ChannelsLast(output_channels=n_channels, time_steps=n_steps_output)\n",
    "\n",
    "model = EncoderProcessorDecoder.from_encoder_processor_decoder(\n",
    "    encoder_decoder=EncoderDecoder.from_encoder_decoder(\n",
    "        encoder=encoder, decoder=decoder\n",
    "    ),\n",
    "    processor=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 50, 50, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Run trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type           | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss_func       | MSELoss        | 0      | train\n",
      "1 | encoder_decoder | EncoderDecoder | 0      | train\n",
      "2 | processor       | FNOProcessor   | 2.4 M  | train\n",
      "-----------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.642     Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a1f3b23c064b67acff4c48ac5dca38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4113c640afc0426b8ad15533052d1090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e09b90c19f3490c851eb7f2a7aee8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111202240b11446c848a5bcf90d1dcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa61d9163a479a86e612846e226b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b108875d2545309fa25bfca6d4d561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33608684584647239d58a332d83eed58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f99a81e6afa4a70aea52597b176b4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1762e0a8231449208b301c07ea9978d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fb7e0d6ce84a8680cfcb974c787e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e60089d7b4414bb816e6c2ddcd951d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f50e335a90473d89a773b71ef2e84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "device = \"mps\"  # \"cpu\"\n",
    "# device = \"cpu\"\n",
    "trainer = L.Trainer(max_epochs=10, accelerator=device, log_every_n_steps=10)\n",
    "trainer.fit(model, datamodule.train_dataloader(), datamodule.val_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Run the evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9c49c42dd64d3692cc13fb524c79cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "        test_loss          0.0004150373861193657\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0004150373861193657}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Example rollout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single element is the full trajectory\n",
    "batch = next(iter(datamodule.rollout_test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 50, 50, 1])\n",
      "torch.Size([1, 316, 50, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "# First n_steps_input are inputs\n",
    "print(batch.input_fields.shape)\n",
    "# Remaining n_steps_output are outputs\n",
    "print(batch.output_fields.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run rollout on one trajectory\n",
    "preds, trues = model.rollout(batch, free_running_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8265cff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'n_spatial_dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m preds.shape == trues.shape\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mse_error = \u001b[43mMSE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/autocast/auto-cast/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/autocast/auto-cast/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/autocast/auto-cast/.venv/lib/python3.12/site-packages/the_well/benchmark/metrics/common.py:36\u001b[39m, in \u001b[36mMetric.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, torch.Tensor), \u001b[33m\"\u001b[39m\u001b[33my must be a torch.Tensor or np.ndarray\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Check dimensions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m n_spatial_dims = \u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_spatial_dims\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m x.ndim >= n_spatial_dims + \u001b[32m1\u001b[39m, (\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mx must have at least n_spatial_dims + 1 dimensions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m )\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m y.ndim >= n_spatial_dims + \u001b[32m1\u001b[39m, (\n\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33my must have at least n_spatial_dims + 1 dimensions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'n_spatial_dims'"
     ]
    }
   ],
   "source": [
    "assert preds.shape == trues.shape\n",
    "mse_error = MSE()(preds, trues, trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1, 50, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1, 50, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "assert trues is not None\n",
    "print(trues.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6dd2c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'WellMetadata' has no attribute 'n_spatial_dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthe_well\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbenchmark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RMSE, MAE, MSE\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthe_well\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WellMetadata\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m rmse_error = \u001b[43mRMSE\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWellMetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/autocast/auto-cast/.venv/lib/python3.12/site-packages/the_well/benchmark/metrics/spatial.py:143\u001b[39m, in \u001b[36mRMSE.eval\u001b[39m\u001b[34m(x, y, meta)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval\u001b[39m(\n\u001b[32m    125\u001b[39m     x: torch.Tensor | np.ndarray,\n\u001b[32m    126\u001b[39m     y: torch.Tensor | np.ndarray,\n\u001b[32m    127\u001b[39m     meta: WellMetadata,\n\u001b[32m    128\u001b[39m ) -> torch.Tensor:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    Root Mean Squared Error\u001b[39;00m\n\u001b[32m    131\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m \u001b[33;03m        Root mean squared error between x and y.\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.sqrt(\u001b[43mMSE\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/autocast/auto-cast/.venv/lib/python3.12/site-packages/the_well/benchmark/metrics/spatial.py:63\u001b[39m, in \u001b[36mMSE.eval\u001b[39m\u001b[34m(x, y, meta)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval\u001b[39m(\n\u001b[32m     48\u001b[39m     x: torch.Tensor | np.ndarray,\n\u001b[32m     49\u001b[39m     y: torch.Tensor | np.ndarray,\n\u001b[32m     50\u001b[39m     meta: WellMetadata,\n\u001b[32m     51\u001b[39m ) -> torch.Tensor:\n\u001b[32m     52\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    Mean Squared Error\u001b[39;00m\n\u001b[32m     54\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \u001b[33;03m        Mean squared error between x and y.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     n_spatial_dims = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(-\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_spatial_dims\u001b[49m - \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m))\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.mean((x - y) ** \u001b[32m2\u001b[39m, dim=n_spatial_dims)\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'WellMetadata' has no attribute 'n_spatial_dims'"
     ]
    }
   ],
   "source": [
    "from the_well.benchmark.metrics import RMSE, MAE, MSE\n",
    "from the_well.data.datasets import WellMetadata\n",
    "\n",
    "rmse_error = RMSE.eval(preds, trues, WellMetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6c6105e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'WellMetadata' has no attribute 'n_spatial_dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mWellMetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_spatial_dims\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'WellMetadata' has no attribute 'n_spatial_dims'"
     ]
    }
   ],
   "source": [
    "WellMetadata.n_spatial_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f450db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-cast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
